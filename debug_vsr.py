#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘è¶…åˆ†è¾¨ç‡è°ƒè¯•è„šæœ¬
ç”¨äºè¯Šæ–­å’Œä¿®å¤è¶…åˆ†è¾¨ç‡é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
import cv2
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('codes')

from models import define_model
from utils import data_utils, base_utils


def debug_data_processing():
    """è°ƒè¯•æ•°æ®å¤„ç†æµç¨‹"""
    print("ğŸ” è°ƒè¯•æ•°æ®å¤„ç†æµç¨‹...")
    
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
    print(f"åŸå§‹å›¾åƒèŒƒå›´: [{test_image.min()}, {test_image.max()}]")
    print(f"åŸå§‹å›¾åƒå½¢çŠ¶: {test_image.shape}")
    
    # æµ‹è¯•canonicalizeå‡½æ•°
    canonicalized = data_utils.canonicalize(test_image)
    print(f"å½’ä¸€åŒ–åèŒƒå›´: [{canonicalized.min():.3f}, {canonicalized.max():.3f}]")
    print(f"å½’ä¸€åŒ–åå½¢çŠ¶: {canonicalized.shape}")
    
    # æµ‹è¯•float32_to_uint8å‡½æ•°
    converted_back = data_utils.float32_to_uint8(canonicalized.numpy())
    print(f"è½¬æ¢å›uint8èŒƒå›´: [{converted_back.min()}, {converted_back.max()}]")
    
    return True


def debug_model_loading():
    """è°ƒè¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ” è°ƒè¯•æ¨¡å‹åŠ è½½...")
    
    try:
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_file = 'experiments_BD/EGVSR/001/test.yml'
        if not os.path.exists(config_file):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False
            
        with open(config_file, 'r', encoding='utf-8') as f:
            opt = yaml.load(f.read(), Loader=yaml.FullLoader)
        
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        model_file = 'pretrained_models/EGVSR_iter420000.pth'
        if not os.path.exists(model_file):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
            return False
            
        print("âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
        
        # è®¾ç½®æ¨¡å‹å‚æ•°
        opt['model']['name'] = 'tecogan'
        opt['model']['generator']['load_path'] = model_file
        opt['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'
        opt['is_train'] = False
        opt['verbose'] = False
        
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {opt['device']}")
        
        # åˆ›å»ºæ¨¡å‹
        model = define_model(opt)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def debug_inference(model):
    """è°ƒè¯•æ¨ç†è¿‡ç¨‹"""
    print("\nğŸ” è°ƒè¯•æ¨ç†è¿‡ç¨‹...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size, channels, height, width = 1, 3, 64, 64
        test_data = np.random.randint(0, 255, (batch_size, height, width, channels), dtype=np.uint8)
        
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
        print(f"æµ‹è¯•æ•°æ®èŒƒå›´: [{test_data.min()}, {test_data.max()}]")
        
        # ä½¿ç”¨æ­£ç¡®çš„æ•°æ®å¤„ç†
        test_tensor = data_utils.canonicalize(test_data)
        print(f"å¤„ç†åæ•°æ®èŒƒå›´: [{test_tensor.min():.3f}, {test_tensor.max():.3f}]")
        
        # æ¨ç†
        with torch.no_grad():
            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            if hasattr(model, 'net_G'):
                model.net_G.eval()
            
            print(f"è¾“å…¥tensorå½¢çŠ¶: {test_tensor.shape}")
            print(f"è¾“å…¥tensorè®¾å¤‡: {test_tensor.device}")
            
            try:
                output = model.infer(test_tensor)
                print(f"è¾“å‡ºç±»å‹: {type(output)}")
                if isinstance(output, torch.Tensor):
                    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
                    if output.numel() > 0:
                        print(f"è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
                    else:
                        print("è¾“å‡ºä¸ºç©ºtensor")
                elif isinstance(output, np.ndarray):
                    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
                    if output.size > 0:
                        print(f"è¾“å‡ºèŒƒå›´: [{output.min()}, {output.max()}]")
                    else:
                        print("è¾“å‡ºä¸ºç©ºæ•°ç»„")
            except Exception as e:
                print(f"æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def debug_video_processing():
    """è°ƒè¯•è§†é¢‘å¤„ç†"""
    print("\nğŸ” è°ƒè¯•è§†é¢‘å¤„ç†...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•è§†é¢‘
    test_video = "1.jpg"  # ä½¿ç”¨æµ‹è¯•å›¾åƒ
    
    if not os.path.exists(test_video):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_video}")
        print("è¯·ç¡®ä¿æµ‹è¯•æ•°æ®é›†å·²ä¸‹è½½")
        return False
    
    try:
        # è¯»å–æµ‹è¯•å›¾åƒ
        test_image = cv2.imread(test_video)
        if test_image is None:
            print("âŒ æ— æ³•è¯»å–æµ‹è¯•å›¾åƒ")
            return False
            
        test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)
        print(f"æµ‹è¯•å›¾åƒå½¢çŠ¶: {test_image.shape}")
        
        # åˆ›å»ºä½åˆ†è¾¨ç‡ç‰ˆæœ¬
        h, w = test_image.shape[:2]
        lr_h, lr_w = h // 4, w // 4
        lr_image = cv2.resize(test_image, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
        
        print(f"ä½åˆ†è¾¨ç‡å›¾åƒå½¢çŠ¶: {lr_image.shape}")
        
        # è½¬æ¢ä¸ºtensor
        lr_tensor = data_utils.canonicalize(lr_image[np.newaxis, ...])
        print(f"Tensorå½¢çŠ¶: {lr_tensor.shape}")
        print(f"TensorèŒƒå›´: [{lr_tensor.min():.3f}, {lr_tensor.max():.3f}]")
        
        return True
        
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ è§†é¢‘è¶…åˆ†è¾¨ç‡è°ƒè¯•å·¥å…·")
    print("=" * 50)
    
    # 1. è°ƒè¯•æ•°æ®å¤„ç†
    if not debug_data_processing():
        print("âŒ æ•°æ®å¤„ç†è°ƒè¯•å¤±è´¥")
        return
    
    # 2. è°ƒè¯•æ¨¡å‹åŠ è½½
    model = debug_model_loading()
    if not model:
        print("âŒ æ¨¡å‹åŠ è½½è°ƒè¯•å¤±è´¥")
        return
    
    # 3. è°ƒè¯•æ¨ç†
    if not debug_inference(model):
        print("âŒ æ¨ç†è°ƒè¯•å¤±è´¥")
        return
    
    # 4. è°ƒè¯•è§†é¢‘å¤„ç†
    if not debug_video_processing():
        print("âŒ è§†é¢‘å¤„ç†è°ƒè¯•å¤±è´¥")
        return
    
    print("\nâœ… æ‰€æœ‰è°ƒè¯•æµ‹è¯•é€šè¿‡ï¼")
    print("\nğŸ’¡ å¦‚æœä»ç„¶æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š")
    print("1. é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶æ˜¯å¦æ­£ç¡®")
    print("2. è¾“å…¥è§†é¢‘è´¨é‡æ˜¯å¦è¶³å¤Ÿå¥½")
    print("3. GPUå†…å­˜æ˜¯å¦å……è¶³")
    print("4. æ¨¡å‹é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®")


if __name__ == "__main__":
    main() 