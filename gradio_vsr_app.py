import os
import sys
import torch
import numpy as np
import cv2
import gradio as gr
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('codes')

from models import define_model
from utils import data_utils, base_utils


class FixedVSRApp:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.model_name = None
        
    def load_model(self, model_name: str):
        """åŠ è½½æŒ‡å®šçš„æ¨¡å‹"""
        if self.model_name == model_name and self.model is not None:
            return self.model
            
        # æ¨¡å‹é…ç½®
        model_configs = {
            'EGVSR': {
                'model_name': 'tecogan',
                'config_file': 'experiments_BD/EGVSR/001/test.yml',
                'checkpoint': 'pretrained_models/EGVSR_iter420000.pth'
            },
            'TecoGAN': {
                'model_name': 'tecogan', 
                'config_file': 'experiments_BD/TecoGAN/001/test.yml',
                'checkpoint': 'pretrained_models/TecoGAN_BD_iter500000.pth'
            },
            'FRVSR': {
                'model_name': 'frvsr',
                'config_file': 'experiments_BD/FRVSR/001/test.yml', 
                'checkpoint': 'pretrained_models/FRVSR_BD_iter400000.pth'
            }
        }
        
        if model_name not in model_configs:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            
        config = model_configs[model_name]
        
        try:
            # è¯»å–é…ç½®æ–‡ä»¶
            with open(config['config_file'], 'r', encoding='utf-8') as f:
                opt = yaml.load(f.read(), Loader=yaml.FullLoader)
            
            # è®¾ç½®æ¨¡å‹å‚æ•°
            opt['model']['name'] = config['model_name']
            opt['model']['generator']['load_path'] = config['checkpoint']
            opt['device'] = str(self.device)
            opt['is_train'] = False
            opt['verbose'] = False
            
            # åˆ›å»ºæ¨¡å‹
            self.model = define_model(opt)
            self.model_name = model_name
            
            return self.model
            
        except Exception as e:
            raise ValueError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
    
    def extract_frames(self, video_path: str) -> tuple:
        """ä»è§†é¢‘ä¸­æå–å¸§"""
        cap = cv2.VideoCapture(video_path)
        frames = []
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # è½¬æ¢ä¸ºRGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame_rgb)
            frame_count += 1
            
        cap.release()
        
        return frames, fps
    
    def create_low_resolution_frames(self, frames: list, scale: int = 4, method: str = 'bicubic') -> list:
        """åˆ›å»ºä½åˆ†è¾¨ç‡å¸§"""
        lr_frames = []
        for frame in frames:
            h, w = frame.shape[:2]
            lr_h, lr_w = h // scale, w // scale
            
            if method == 'bicubic':
                lr_frame = cv2.resize(frame, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
            elif method == 'bilinear':
                lr_frame = cv2.resize(frame, (lr_w, lr_h), interpolation=cv2.INTER_LINEAR)
            elif method == 'nearest':
                lr_frame = cv2.resize(frame, (lr_w, lr_h), interpolation=cv2.INTER_NEAREST)
            else:
                lr_frame = cv2.resize(frame, (lr_w, lr_h), interpolation=cv2.INTER_CUBIC)
                
            lr_frames.append(lr_frame)
        return lr_frames
    
    def process_video_fixed(self, video_path: str, model_name: str, max_frames: int = 20, 
                           create_lr: bool = True, downscale_method: str = 'bicubic'):
        """ä¿®å¤ç‰ˆæœ¬çš„è§†é¢‘å¤„ç†"""
        try:
            # åŠ è½½æ¨¡å‹
            model = self.load_model(model_name)
            
            # æå–å¸§
            frames, fps = self.extract_frames(video_path)
            if not frames:
                raise ValueError("æ— æ³•ä»è§†é¢‘ä¸­æå–å¸§")
            
            # æ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦åˆ›å»ºä½åˆ†è¾¨ç‡å¸§
            if create_lr:
                # åˆ›å»ºä½åˆ†è¾¨ç‡å¸§ç”¨äºæ¼”ç¤º
                lr_frames = self.create_low_resolution_frames(frames, method=downscale_method)
                input_frames = lr_frames
                print(f"åˆ›å»ºä½åˆ†è¾¨ç‡è¾“å…¥: {len(input_frames)} å¸§")
                print(f"ä½åˆ†è¾¨ç‡å°ºå¯¸: {input_frames[0].shape}")
            else:
                # ç›´æ¥ä½¿ç”¨åŸå§‹å¸§ï¼Œä¸è¿›è¡Œä»»ä½•ä¸‹é‡‡æ ·
                input_frames = frames
                print(f"ç›´æ¥ä½¿ç”¨åŸå§‹è¾“å…¥: {len(input_frames)} å¸§")
                print(f"åŸå§‹å°ºå¯¸: {input_frames[0].shape}")
            
            print(f"å°†å¤„ç†å®Œæ•´è§†é¢‘çš„ {len(input_frames)} å¸§è¿›è¡Œè¶…åˆ†è¾¨ç‡")
            
            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æ•°æ®å¤„ç†æµç¨‹
            # 1. å †å å¸§
            stacked_frames = np.stack(input_frames)  # (T, H, W, C)
            
            # 2. ä½¿ç”¨é¡¹ç›®çš„æ•°æ®å¤„ç†å·¥å…·è¿›è¡Œæ­£ç¡®çš„æ•°æ®è½¬æ¢
            input_tensor = data_utils.canonicalize(stacked_frames)  # å½’ä¸€åŒ–åˆ°[0,1]
            
            print(f"è¾“å…¥tensorå½¢çŠ¶: {input_tensor.shape}")
            print(f"è¾“å…¥tensorèŒƒå›´: [{input_tensor.min():.3f}, {input_tensor.max():.3f}]")
            
            # 3. æ¨ç†
            with torch.no_grad():
                # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
                if hasattr(model, 'net_G'):
                    model.net_G.eval()
                sr_frames = model.infer(input_tensor)
            
            # 4. å¤„ç†è¾“å‡º - æ¨¡å‹è¾“å‡ºå·²ç»æ˜¯uint8æ ¼å¼
            if isinstance(sr_frames, torch.Tensor):
                sr_frames = sr_frames.cpu().numpy()
            
            print(f"è¾“å‡ºå½¢çŠ¶: {sr_frames.shape}")
            print(f"è¾“å‡ºèŒƒå›´: [{sr_frames.min()}, {sr_frames.max()}]")
            
            # 5. ç¡®ä¿è¾“å‡ºæ˜¯uint8æ ¼å¼å¹¶éªŒè¯å¸§åºåˆ—
            sr_frames = np.clip(sr_frames, 0, 255).astype(np.uint8)
            sr_frames_list = [frame for frame in sr_frames]
            
            # éªŒè¯å¸§åºåˆ—
            print(f"è¶…åˆ†å¸§åºåˆ—ä¿¡æ¯:")
            print(f"  - æ€»å¸§æ•°: {len(sr_frames_list)}")
            print(f"  - ç¬¬ä¸€å¸§å½¢çŠ¶: {sr_frames_list[0].shape}")
            print(f"  - ç¬¬ä¸€å¸§èŒƒå›´: [{sr_frames_list[0].min()}, {sr_frames_list[0].max()}]")
            print(f"  - æœ€åä¸€å¸§å½¢çŠ¶: {sr_frames_list[-1].shape}")
            print(f"  - æœ€åä¸€å¸§èŒƒå›´: [{sr_frames_list[-1].min()}, {sr_frames_list[-1].max()}]")
            
            # æ£€æŸ¥å¸§åºåˆ—æ˜¯å¦ä¸€è‡´
            if len(sr_frames_list) != len(input_frames):
                print(f"è­¦å‘Š: è¾“å…¥å¸§æ•°({len(input_frames)})ä¸è¾“å‡ºå¸§æ•°({len(sr_frames_list)})ä¸åŒ¹é…")
            
            # 6. åˆ›å»ºè¾“å‡ºè§†é¢‘ - ä¿®å¤ç‰ˆæœ¬
            output_path = video_path.replace('.mp4', '_sr.mp4')
            h, w = sr_frames[0].shape[:2]
            
            # å°è¯•ä¸åŒçš„ç¼–ç å™¨
            try:
                # é¦–å…ˆå°è¯• H.264 ç¼–ç å™¨
                fourcc = cv2.VideoWriter_fourcc(*'H264')
                out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
                if not out.isOpened():
                    raise Exception("H264ç¼–ç å™¨ä¸å¯ç”¨")
            except:
                try:
                    # å°è¯• XVID ç¼–ç å™¨
                    output_path = video_path.replace('.mp4', '_sr.avi')
                    fourcc = cv2.VideoWriter_fourcc(*'XVID')
                    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
                    if not out.isOpened():
                        raise Exception("XVIDç¼–ç å™¨ä¸å¯ç”¨")
                except:
                    # æœ€åä½¿ç”¨ MJPG ç¼–ç å™¨
                    output_path = video_path.replace('.mp4', '_sr.avi')
                    fourcc = cv2.VideoWriter_fourcc(*'MJPG')
                    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
            
            print(f"åˆ›å»ºè§†é¢‘: {output_path}, å°ºå¯¸: {w}x{h}, FPS: {fps}")
            print(f"è¶…åˆ†å¸§æ•°é‡: {len(sr_frames)}")
            
            # å†™å…¥å¸§ï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
            for i, frame in enumerate(sr_frames):
                # ç¡®ä¿å¸§æ˜¯RGBæ ¼å¼
                if frame.shape[2] == 3:
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                else:
                    frame_bgr = frame
                
                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                frame_bgr = frame_bgr.astype(np.uint8)
                
                # å†™å…¥å¸§
                success = out.write(frame_bgr)
                if not success:
                    print(f"è­¦å‘Š: ç¬¬{i}å¸§å†™å…¥å¤±è´¥")
                
            out.release()
            print(f"è§†é¢‘åˆ›å»ºå®Œæˆ: {output_path}")
            
            # ä¿å­˜å‰å‡ å¸§ç”¨äºéªŒè¯
            try:
                debug_dir = "debug_frames"
                os.makedirs(debug_dir, exist_ok=True)
                
                # ä¿å­˜å‰3å¸§ç”¨äºå¯¹æ¯”
                for i in range(min(3, len(sr_frames_list))):
                    # ä¿å­˜è¶…åˆ†å¸§
                    sr_frame_path = os.path.join(debug_dir, f"sr_frame_{i:03d}.png")
                    cv2.imwrite(sr_frame_path, cv2.cvtColor(sr_frames_list[i], cv2.COLOR_RGB2BGR))
                    
                    # ä¿å­˜å¯¹åº”çš„è¾“å…¥å¸§
                    if i < len(input_frames):
                        input_frame_path = os.path.join(debug_dir, f"input_frame_{i:03d}.png")
                        cv2.imwrite(input_frame_path, cv2.cvtColor(input_frames[i], cv2.COLOR_RGB2BGR))
                
                print(f"è°ƒè¯•å¸§å·²ä¿å­˜åˆ° {debug_dir} ç›®å½•")
            except Exception as e:
                print(f"ä¿å­˜è°ƒè¯•å¸§å¤±è´¥: {str(e)}")
            
            # è¿”å›ç»“æœ
            if create_lr:
                return output_path, lr_frames[:max_frames], sr_frames_list[:max_frames], None
            else:
                return output_path, frames[:max_frames], sr_frames_list[:max_frames], None
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise gr.Error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")


def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    app = FixedVSRApp()
    
    with gr.Blocks(title="ä¿®å¤ç‰ˆè§†é¢‘è¶…åˆ†è¾¨ç‡ç³»ç»Ÿ") as interface:
        gr.Markdown("# ğŸ¬ ä¿®å¤ç‰ˆè§†é¢‘è¶…åˆ†è¾¨ç‡ç³»ç»Ÿ")
        gr.Markdown("ä¿®å¤äº†è¶…åˆ†ç»“æœåªæœ‰è½®å»“çš„é—®é¢˜")
        
        with gr.Row():
            with gr.Column():
                video_input = gr.Video(label="è¾“å…¥è§†é¢‘")
                model_selector = gr.Dropdown(
                    choices=['EGVSR', 'TecoGAN', 'FRVSR'],
                    value="EGVSR",
                    label="é€‰æ‹©æ¨¡å‹"
                )
                max_frames = gr.Slider(
                    minimum=5,
                    maximum=30,
                    value=20,
                    step=5,
                    label="æœ€å¤§å¤„ç†å¸§æ•°"
                )
                
                # æ·»åŠ æ–°çš„é€‰é¡¹
                with gr.Row():
                    create_lr_checkbox = gr.Checkbox(
                        value=False,
                        label="åˆ›å»ºä½åˆ†è¾¨ç‡è¾“å…¥ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"
                    )
                    downscale_method = gr.Dropdown(
                        choices=['bicubic', 'bilinear', 'nearest'],
                        value='bicubic',
                        label="ä¸‹é‡‡æ ·æ–¹æ³•"
                    )
                
                process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary")
            
            with gr.Column():
                video_output = gr.Video(label="è¶…åˆ†è¾¨ç‡ç»“æœ")
                status_text = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
        
        # å¸§å¯¹æ¯”
        with gr.Row():
            with gr.Column():
                gr.Markdown("### è¾“å…¥å¸§")
                input_gallery = gr.Gallery(label="è¾“å…¥å¸§", show_label=False)
            with gr.Column():
                gr.Markdown("### è¶…åˆ†è¾¨ç‡å¸§")
                sr_gallery = gr.Gallery(label="è¶…åˆ†è¾¨ç‡å¸§", show_label=False)
        
        def process_video_wrapper(video_path, model_name, max_frames, create_lr, downscale_method):
            if video_path is None:
                return None, [], [], "è¯·å…ˆä¸Šä¼ è§†é¢‘"
            
            try:
                # å¤„ç†å®Œæ•´çš„è§†é¢‘ï¼ˆä½¿ç”¨max_frameså‚æ•°ï¼‰
                result = app.process_video_fixed(video_path, model_name, max_frames, create_lr, downscale_method)
                output_path, input_frames, sr_frames, _ = result
                
                if create_lr:
                    status_msg = f"å¤„ç†å®Œæˆï¼å·²åˆ›å»ºä½åˆ†è¾¨ç‡è¾“å…¥è¿›è¡Œè¶…åˆ†è¾¨ç‡æ¼”ç¤ºã€‚å¤„ç†äº† {len(sr_frames)} å¸§ã€‚"
                else:
                    status_msg = f"å¤„ç†å®Œæˆï¼ç›´æ¥å¯¹åŸå§‹è§†é¢‘è¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†ã€‚å¤„ç†äº† {len(sr_frames)} å¸§ã€‚"
                
                # åªåœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºå‰30å¸§ï¼Œä½†å®é™…å¤„ç†äº†å®Œæ•´çš„è§†é¢‘
                max_display_frames = 30
                input_frames_to_show = input_frames[:max_display_frames]
                sr_frames_to_show = sr_frames[:max_display_frames]
                
                return output_path, input_frames_to_show, sr_frames_to_show, status_msg
            except Exception as e:
                import traceback
                traceback.print_exc()
                return None, [], [], f"å¤„ç†å¤±è´¥: {str(e)}"
        
        process_btn.click(
            process_video_wrapper,
            inputs=[video_input, model_selector, max_frames, create_lr_checkbox, downscale_method],
            outputs=[video_output, input_gallery, sr_gallery, status_text]
        )
        
        # æ·»åŠ è¯´æ˜
        with gr.Accordion("â„¹ï¸ ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### é‡è¦è¯´æ˜ï¼š
            
            **"åˆ›å»ºä½åˆ†è¾¨ç‡è¾“å…¥"é€‰é¡¹è¯´æ˜ï¼š**
            
            âœ… **å‹¾é€‰**ï¼š
            - è‡ªåŠ¨å°†è¾“å…¥è§†é¢‘ä¸‹é‡‡æ ·4å€ï¼Œç„¶åè¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†
            - é€‚ç”¨äºæ¼”ç¤ºè¶…åˆ†è¾¨ç‡æ•ˆæœ
            - å¯ä»¥å¯¹æ¯”åŸå§‹é«˜åˆ†è¾¨ç‡å¸§å’Œè¶…åˆ†ç»“æœ
            - é€‚åˆé«˜åˆ†è¾¨ç‡è¾“å…¥è§†é¢‘
            
            âŒ **ä¸å‹¾é€‰**ï¼š
            - ç›´æ¥ä½¿ç”¨åŸå§‹è§†é¢‘å°ºå¯¸ï¼Œä¸è¿›è¡Œä»»ä½•ä¸‹é‡‡æ ·
            - é€‚ç”¨äºå·²ç»æ˜¯ä½åˆ†è¾¨ç‡çš„è¾“å…¥è§†é¢‘
            - å¦‚æœè¾“å…¥æ˜¯é«˜åˆ†è¾¨ç‡è§†é¢‘ï¼Œä¼šç›´æ¥è¿›è¡Œè¶…åˆ†å¤„ç†
            
            ### ä¿®å¤çš„é—®é¢˜ï¼š
            1. **æ•°æ®èŒƒå›´é—®é¢˜**: ä½¿ç”¨ `data_utils.canonicalize()` æ­£ç¡®å½’ä¸€åŒ–æ•°æ®åˆ°[0,1]èŒƒå›´
            2. **æ•°æ®æ ¼å¼é—®é¢˜**: ç¡®ä¿è¾“å…¥tensoræ ¼å¼æ­£ç¡® (T, H, W, C)
            3. **è§†é¢‘ç¼–ç é—®é¢˜**: æ”¯æŒå¤šç§ç¼–ç å™¨ï¼Œç¡®ä¿è§†é¢‘æ­£ç¡®ç”Ÿæˆ
            4. **å¸§åºåˆ—é—®é¢˜**: éªŒè¯è¾“å…¥è¾“å‡ºå¸§æ•°åŒ¹é…
            
            ### ä½¿ç”¨å»ºè®®ï¼š
            - æƒ³è¦æ¼”ç¤ºè¶…åˆ†æ•ˆæœï¼šå‹¾é€‰"åˆ›å»ºä½åˆ†è¾¨ç‡è¾“å…¥"
            - å¤„ç†ä½åˆ†è¾¨ç‡è§†é¢‘ï¼šä¸å‹¾é€‰ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å°ºå¯¸
            - æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºçš„è°ƒè¯•ä¿¡æ¯
            - æ£€æŸ¥ `debug_frames` ç›®å½•ä¸­çš„å¯¹æ¯”å¸§
            """)
        
        gr.Markdown("---")
        gr.Markdown("åŸºäº [EGVSR-PyTorch](https://github.com/Thmen/EGVSR) é¡¹ç›®æ„å»º")
    
    return interface


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import gradio
        print("âœ… Gradio å·²å®‰è£…")
    except ImportError:
        print("âŒ è¯·å…ˆå®‰è£… Gradio: pip install gradio")
        sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        "pretrained_models/EGVSR_iter420000.pth",
        "pretrained_models/TecoGAN_BD_iter500000.pth",
        "pretrained_models/FRVSR_BD_iter400000.pth"
    ]
    
    missing_files = []
    for file_path in model_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        print("âš ï¸  è­¦å‘Š: ä»¥ä¸‹é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ç¼ºå¤±:")
        for file_path in missing_files:
            print(f"   - {file_path}")
        print("è¯·ä¸‹è½½ç›¸åº”çš„é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶åˆ° pretrained_models ç›®å½•")
    
    # å¯åŠ¨åº”ç”¨
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    ) 